{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andoni.sudupe/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "os.chdir('/shared/home/andoni.sudupe/mHubert_finetune')\n",
    "\n",
    "from scripts.utils import load_data, setup_processor\n",
    "from finetune_hubert import train_model\n",
    "from transformers import (\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Processor,\n",
    "    HubertForCTC,\n",
    ")\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/shared/home/andoni.sudupe/mHubert_finetune'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 387426\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 16359\n",
      "    })\n",
      "    test_cv: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 14312\n",
      "    })\n",
      "    test_parl: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 1521\n",
      "    })\n",
      "    test_oslr: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 526\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 1691\n",
      "    })\n",
      "    dev_cv: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 620\n",
      "    })\n",
      "    dev_parl: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 550\n",
      "    })\n",
      "    dev_oslr: Dataset({\n",
      "        features: ['input_values', 'labels'],\n",
      "        num_rows: 521\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data = load_data('/home/andoni.sudupe/mHubert_finetune/data/preprocessed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/home/andoni.sudupe/mHubert_finetune/checkpoints/mHubert-ASR-eu/checkpoint-43000'\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    '/home/andoni.sudupe/mHubert_finetune/data/vocab.json', \n",
    "    unk_token=\"[UNK]\", \n",
    "    pad_token=\"[PAD]\", \n",
    "    word_delimiter_token=\"|\"\n",
    ")\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Combine into processor\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "model = HubertForCTC.from_pretrained(model_name, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_result(batch, model, processor):\n",
    "    \"\"\"Map model predictions to text for evaluation.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        input_values = torch.tensor(batch[\"input_values\"], device=device).unsqueeze(0)\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n",
    "    batch[\"text\"] = processor.decode(batch[\"labels\"], group_tokens=False)\n",
    "\n",
    "    return batch\n",
    "\n",
    "def evaluate_model(data, model, processor):\n",
    "    \"\"\"Evaluate the trained model on test data.\"\"\"\n",
    "    # Move model to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define mapping function for evaluation\n",
    "    map_fn = lambda batch: map_to_result(batch, model, processor)\n",
    "    \n",
    "    # Apply mapping function to test data\n",
    "    results = data.map(map_fn, remove_columns=data.column_names)\n",
    "    \n",
    "    # Calculate WER\n",
    "    wer_metric = load(\"wer\", trust_remote_code=True)\n",
    "    cer_metric = load(\"cer\", trust_remote_code=True)\n",
    "\n",
    "    test_wer = wer_metric.compute(predictions=results[\"pred_str\"], references=results[\"text\"])\n",
    "    test_cer = cer_metric.compute(predictions=results[\"pred_str\"], references=results[\"text\"])\n",
    "\n",
    "    print(f\"\\nTest WER: {test_wer:.3f}\")\n",
    "    print(f\"\\nTest CER: {test_cer:.3f}\")\n",
    "    \n",
    "    # Display sample predictions\n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i in range(min(5, len(results))):\n",
    "        print(f\"Reference: {results['text'][i]}\")\n",
    "        print(f\"Prediction: {results['pred_str'][i]}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function evaluate_model.<locals>.<lambda> at 0x7ff58f2ea2a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 10/10 [00:18<00:00,  1.88s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test WER: 1.000\n",
      "\n",
      "Test CER: 0.962\n",
      "\n",
      "Sample predictions:\n",
      "Reference: honek garrantzi handia zuen ehun urteko gerran\n",
      "Prediction: \n",
      "---\n",
      "Reference: osasuna aurkari zuzena da eta beraz puntuek balio bikoitza dute\n",
      "Prediction: iiiiaaa\n",
      "---\n",
      "Reference: irungo familia boteretsu bat da olazabal familia\n",
      "Prediction: i\n",
      "---\n",
      "Reference: hezkuntzak prestatu zituen probak pisa eta antzekoak eredu\n",
      "Prediction: iiiiiiiii i i  ai\n",
      "---\n",
      "Reference: bestalde botilek abangoardiako diseinu orijinalak dituzte\n",
      "Prediction: \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(data['test_cv'].select(range(10)), model, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: new yorkeko aireportuan eskala egin genuen kaliforniara bidean\n",
      "Prediction: niu jorkeko aire portuan eskal aegin genuen kaliforniarabidean\n",
      "---\n",
      "Reference: janet jackson michael jackson abeslari ospetsuaren arreba da\n",
      "Prediction: jane jacxon maycel jacxon abeslari ospesuaren arrebada\n",
      "---\n",
      "Reference: londreseko heathrow aireportua munduko handienetarikoena da\n",
      "Prediction: londrexeko itroua ireportua munduko handienetarikoa da\n",
      "---\n",
      "Reference: hamabietan izango da txupinazoa eta udaletxeko balkoitik botako dute urtero bezala\n",
      "Prediction: hamabietan izango da txupinasoa eta udaletzeko palkoitik botako dute urtero bezala\n",
      "---\n",
      "Reference: motorolaren telefono berria erostekotan nabil\n",
      "Prediction: motrolaren telefono berria erostekotan nabil\n",
      "---\n",
      "Reference: ekuadorretik igaro ginen bidaia hartan\n",
      "Prediction: ekuadorretik igaro ginen bidai hartan\n",
      "---\n",
      "Reference: lau bat bat bi bat bi zazpi zortzi bi hiru hiru hiru zero\n",
      "Prediction: lau bat bat bi bat bi zazpi zortzi bi hiru hiru hiru zero\n",
      "---\n",
      "Reference: armiñonen san formerio erromeria ospatzen da irailean\n",
      "Prediction: armin honen sanfomerio erromeria ospatzen da irailean\n",
      "---\n",
      "Reference: barack obama presidenteak kargua utzi du zortzi urte igaro eta gero\n",
      "Prediction: barak obama presidenteak kargua utzi du zortzi urte igaro eta gero\n",
      "---\n",
      "Reference: ehun urte ditu mende batek\n",
      "Prediction: ehun urte ditu mende batek\n",
      "---\n",
      "Reference: stevie wonder abeslaria itsua da jaiotzez\n",
      "Prediction: estibiwonderrabeslaria itxua da jaihotzez\n",
      "---\n",
      "Reference: datorren larunbatean lagun baten urtebetetzea ospatuko dugu\n",
      "Prediction: datorren larunbatian lagun baten urte betetzea ospatuko dugu\n",
      "---\n",
      "Reference: zeberio nerbioi ibarraren barruan dago eta ia berrogeita hamar kilometroko azalera dauka\n",
      "Prediction: sebedio nerbioi barraren barruan dago eta ia berrogeita hamar kilometroko azalera dauka\n",
      "---\n",
      "Reference: hershey markako txokolatezko ziropa oso gozoa da\n",
      "Prediction: erzi markakotxo kolatezko ziropea oso gosoa da\n",
      "---\n",
      "Reference: dirutza handiko aktoreak hollywooden bizi dira\n",
      "Prediction: dirutza handiko aktoreak jolibuden bizi dira\n",
      "---\n",
      "Reference: bederatzigarren geltokian jaitsi behar gara trenetik\n",
      "Prediction: bederatzigarren geltokian jaitxi behar gara trenetik\n",
      "---\n",
      "Reference: saskibaloi talde ezaguna du houstonek\n",
      "Prediction: saskibaloi talde ezaguna duusthonek\n",
      "---\n",
      "Reference: laura de la calle durangarrak euskolegas saioan lan egin zuen\n",
      "Prediction: laura de lakaile durangarrak euskolegas saioan lan egin zuen\n",
      "---\n",
      "Reference: iker galartza maisua dugu jendeari barre eragiten\n",
      "Prediction: iker galartza maizua dugu jendeari barre egiten\n",
      "---\n",
      "Reference: iratxe zoriontzeko deitu du amonak\n",
      "Prediction: iratse zoriontzeko odeitu du amonak\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "        print(f\"Reference: {results['text'][i]}\")\n",
    "        print(f\"Prediction: {results['pred_str'][i]}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.60k/5.60k [00:00<00:00, 976kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test CER: 0.075\n"
     ]
    }
   ],
   "source": [
    "cer_metric = load(\"cer\", trust_remote_code=True)\n",
    "\n",
    "test_cer = cer_metric.compute(predictions=results[\"pred_str\"], references=results[\"text\"])\n",
    "\n",
    "print(f\"\\nTest CER: {test_cer:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(repo_id='Ansu/hubert_for_basque')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
