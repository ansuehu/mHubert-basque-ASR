{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/shared/home/andoni.sudupe/mHubert_finetune')\n",
    "\n",
    "from scripts.preprocess import create_vocabulary, load_and_prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 8\n",
      "  Length of train Set: 387426\n",
      "  Length of test_cv Set: 14312\n",
      "  Length of test_parl Set: 1521\n",
      "  Length of test_oslr Set: 526\n",
      "  Length of dev Set: 1691\n",
      "  Length of dev_cv Set: 620\n",
      "  Length of dev_parl Set: 550\n",
      "  Length of dev_oslr Set: 521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 387426/387426 [36:03<00:00, 179.03 examples/s]\n",
      "Map: 100%|██████████| 14312/14312 [01:13<00:00, 193.59 examples/s]\n",
      "Map: 100%|██████████| 1521/1521 [00:09<00:00, 160.54 examples/s]\n",
      "Map: 100%|██████████| 526/526 [00:03<00:00, 135.65 examples/s] \n",
      "Map: 100%|██████████| 1691/1691 [00:10<00:00, 165.82 examples/s]\n",
      "Map: 100%|██████████| 620/620 [00:05<00:00, 116.15 examples/s] \n",
      "Map: 100%|██████████| 550/550 [00:04<00:00, 127.70 examples/s] \n",
      "Map: 100%|██████████| 521/521 [00:04<00:00, 123.89 examples/s] \n"
     ]
    }
   ],
   "source": [
    "data = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/387426 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 387426/387426 [00:05<00:00, 69003.29 examples/s]\n",
      "Map: 100%|██████████| 14312/14312 [00:00<00:00, 240072.30 examples/s]\n",
      "Map: 100%|██████████| 1521/1521 [00:00<00:00, 77094.10 examples/s]\n",
      "Map: 100%|██████████| 526/526 [00:00<00:00, 37159.00 examples/s]\n",
      "Map: 100%|██████████| 1691/1691 [00:00<00:00, 145068.99 examples/s]\n",
      "Map: 100%|██████████| 620/620 [00:00<00:00, 89240.51 examples/s]\n",
      "Map: 100%|██████████| 550/550 [00:00<00:00, 52861.30 examples/s]\n",
      "Map: 100%|██████████| 521/521 [00:00<00:00, 76164.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 32\n",
      "Vocabulary saved to vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'t': 0,\n",
       " 'w': 1,\n",
       " 'f': 2,\n",
       " 'x': 4,\n",
       " 'g': 5,\n",
       " 'e': 6,\n",
       " 'h': 7,\n",
       " 'ã': 8,\n",
       " 'd': 9,\n",
       " 'i': 10,\n",
       " 'l': 11,\n",
       " 'v': 12,\n",
       " 'a': 13,\n",
       " 'u': 14,\n",
       " 'o': 15,\n",
       " 'q': 16,\n",
       " 'z': 17,\n",
       " 'b': 18,\n",
       " 'k': 19,\n",
       " 'j': 20,\n",
       " 'c': 21,\n",
       " 'ñ': 22,\n",
       " 'n': 23,\n",
       " 'p': 24,\n",
       " 's': 25,\n",
       " 'y': 26,\n",
       " '±': 27,\n",
       " 'r': 28,\n",
       " 'm': 29,\n",
       " '|': 3,\n",
       " '[UNK]': 30,\n",
       " '[PAD]': 31}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_vocabulary(data, save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, HubertForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(HubertForCTC.from_pretrained(\"/home/andoni.sudupe/mHubert_finetune/checkpoints/mHubert_basque/checkpoint-45000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HubertForCTC.from_pretrained(\"/home/andoni.sudupe/mHubert_finetune/checkpoints/mHubert-basque-ASR-30ep/checkpoint-302700\", local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        '/home/andoni.sudupe/mHubert_finetune/data/vocab.json', \n",
    "        unk_token=\"[UNK]\", \n",
    "        pad_token=\"[PAD]\", \n",
    "        word_delimiter_token=\"|\"\n",
    "    )\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('/home/andoni.sudupe/mHubert_finetune/checkpoints/mHubert-basque-ASR-30ep/checkpoint-302700')\n",
    "\n",
    "# Combine into processor\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ansu/mHubert-basque-ASR/commit/02a392e5210fa2fe892c7a6c83e4355df5714f0f', commit_message='Upload HubertForCTC', commit_description='', oid='02a392e5210fa2fe892c7a6c83e4355df5714f0f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ansu/mHubert-basque-ASR', endpoint='https://huggingface.co', repo_type='model', repo_id='Ansu/mHubert-basque-ASR'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('Ansu/mHubert-basque-ASR', token = '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ansu/mHubert-basque-ASR/commit/99acbfb35c87b55a26a930aeaeec90cbcca93c31', commit_message='Upload processor', commit_description='', oid='99acbfb35c87b55a26a930aeaeec90cbcca93c31', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ansu/mHubert-basque-ASR', endpoint='https://huggingface.co', repo_type='model', repo_id='Ansu/mHubert-basque-ASR'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.push_to_hub('Ansu/mHubert-basque-ASR', token = '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk('../data/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/100 (samples 0-5)...\n",
      "<class 'int'>\n",
      "[{'path': 'common_voice_eu_39264611.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00024414,\n",
      "       -0.00012207, -0.00012207]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264693.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -1.22070312e-04, -9.15527344e-05, -6.10351562e-05]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264696.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "        0.00000000e+00,  0.00000000e+00, -3.05175781e-05]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264697.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -3.05175781e-05,  6.10351562e-05,  6.10351562e-05]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264698.wav', 'array': array([0.        , 0.        , 0.        , ..., 0.00030518, 0.00024414,\n",
      "       0.00018311]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_38587129.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00027466,\n",
      "       -0.00024414, -0.00021362]), 'sampling_rate': 16000}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(ds['train']), 6):\n",
    "\n",
    "    batch_idx = i // 6\n",
    "    end_idx = min(i + 6, len(ds['train']))\n",
    "    batch_size = end_idx - i\n",
    "    \n",
    "    print(f\"Processing batch {batch_idx+1}/{100} (samples {i}-{end_idx-1})...\")\n",
    "    print(type(end_idx))\n",
    "    # try:\n",
    "        # Get batch and extract features\n",
    "    batch = ds['train'][i:end_idx]\n",
    "    \n",
    "    aaa = batch['audio']\n",
    "\n",
    "    batch_audio = [b[\"array\"] for b in aaa] \n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
