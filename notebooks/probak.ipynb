{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/shared/home/andoni.sudupe/mHubert_finetune')\n",
    "\n",
    "from scripts.preprocess import create_vocabulary, load_and_prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 8\n",
      "  Length of train Set: 387426\n",
      "  Length of test_cv Set: 14312\n",
      "  Length of test_parl Set: 1521\n",
      "  Length of test_oslr Set: 526\n",
      "  Length of dev Set: 1691\n",
      "  Length of dev_cv Set: 620\n",
      "  Length of dev_parl Set: 550\n",
      "  Length of dev_oslr Set: 521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 387426/387426 [36:03<00:00, 179.03 examples/s]\n",
      "Map: 100%|██████████| 14312/14312 [01:13<00:00, 193.59 examples/s]\n",
      "Map: 100%|██████████| 1521/1521 [00:09<00:00, 160.54 examples/s]\n",
      "Map: 100%|██████████| 526/526 [00:03<00:00, 135.65 examples/s] \n",
      "Map: 100%|██████████| 1691/1691 [00:10<00:00, 165.82 examples/s]\n",
      "Map: 100%|██████████| 620/620 [00:05<00:00, 116.15 examples/s] \n",
      "Map: 100%|██████████| 550/550 [00:04<00:00, 127.70 examples/s] \n",
      "Map: 100%|██████████| 521/521 [00:04<00:00, 123.89 examples/s] \n"
     ]
    }
   ],
   "source": [
    "data = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/387426 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 387426/387426 [00:05<00:00, 69003.29 examples/s]\n",
      "Map: 100%|██████████| 14312/14312 [00:00<00:00, 240072.30 examples/s]\n",
      "Map: 100%|██████████| 1521/1521 [00:00<00:00, 77094.10 examples/s]\n",
      "Map: 100%|██████████| 526/526 [00:00<00:00, 37159.00 examples/s]\n",
      "Map: 100%|██████████| 1691/1691 [00:00<00:00, 145068.99 examples/s]\n",
      "Map: 100%|██████████| 620/620 [00:00<00:00, 89240.51 examples/s]\n",
      "Map: 100%|██████████| 550/550 [00:00<00:00, 52861.30 examples/s]\n",
      "Map: 100%|██████████| 521/521 [00:00<00:00, 76164.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 32\n",
      "Vocabulary saved to vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'t': 0,\n",
       " 'w': 1,\n",
       " 'f': 2,\n",
       " 'x': 4,\n",
       " 'g': 5,\n",
       " 'e': 6,\n",
       " 'h': 7,\n",
       " 'ã': 8,\n",
       " 'd': 9,\n",
       " 'i': 10,\n",
       " 'l': 11,\n",
       " 'v': 12,\n",
       " 'a': 13,\n",
       " 'u': 14,\n",
       " 'o': 15,\n",
       " 'q': 16,\n",
       " 'z': 17,\n",
       " 'b': 18,\n",
       " 'k': 19,\n",
       " 'j': 20,\n",
       " 'c': 21,\n",
       " 'ñ': 22,\n",
       " 'n': 23,\n",
       " 'p': 24,\n",
       " 's': 25,\n",
       " 'y': 26,\n",
       " '±': 27,\n",
       " 'r': 28,\n",
       " 'm': 29,\n",
       " '|': 3,\n",
       " '[UNK]': 30,\n",
       " '[PAD]': 31}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_vocabulary(data, save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, HubertForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, HubertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        '/home/andoni.sudupe/mHubert_finetune/data/composite_eu/vocab.json', \n",
    "        unk_token=\"[UNK]\", \n",
    "        pad_token=\"[PAD]\", \n",
    "        word_delimiter_token=\"|\"\n",
    "    )\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('/home/andoni.sudupe/mHubert_finetune/checkpoints/mHubert_basque_70ep/checkpoint-121080')\n",
    "\n",
    "# Combine into processor\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HubertModel.from_pretrained(\"/home/andoni.sudupe/mHubert_finetune/checkpoints/mHubert_basque_70ep/checkpoint-121080\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 378M/378M [00:12<00:00, 29.4MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ansu/mHubert-basque-k1000-L9/commit/63cca50f01c5c70ba9511c20e8119f873b0a2f1b', commit_message='Upload model', commit_description='', oid='63cca50f01c5c70ba9511c20e8119f873b0a2f1b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ansu/mHubert-basque-k1000-L9', endpoint='https://huggingface.co', repo_type='model', repo_id='Ansu/mHubert-basque-k1000-L9'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('Ansu/mHubert-basque-k1000-L9', token = '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ansu/mHubert-basque-k1000-L9/commit/63536c0f07db695d5f32743f1c9b0c96ad8e7b86', commit_message='Upload processor', commit_description='', oid='63536c0f07db695d5f32743f1c9b0c96ad8e7b86', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ansu/mHubert-basque-k1000-L9', endpoint='https://huggingface.co', repo_type='model', repo_id='Ansu/mHubert-basque-k1000-L9'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.push_to_hub('Ansu/mHubert-basque-k1000-L9', token = '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk('../data/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/100 (samples 0-5)...\n",
      "<class 'int'>\n",
      "[{'path': 'common_voice_eu_39264611.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00024414,\n",
      "       -0.00012207, -0.00012207]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264693.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -1.22070312e-04, -9.15527344e-05, -6.10351562e-05]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264696.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "        0.00000000e+00,  0.00000000e+00, -3.05175781e-05]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264697.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -3.05175781e-05,  6.10351562e-05,  6.10351562e-05]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_39264698.wav', 'array': array([0.        , 0.        , 0.        , ..., 0.00030518, 0.00024414,\n",
      "       0.00018311]), 'sampling_rate': 16000}, {'path': 'common_voice_eu_38587129.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00027466,\n",
      "       -0.00024414, -0.00021362]), 'sampling_rate': 16000}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(ds['train']), 6):\n",
    "\n",
    "    batch_idx = i // 6\n",
    "    end_idx = min(i + 6, len(ds['train']))\n",
    "    batch_size = end_idx - i\n",
    "    \n",
    "    print(f\"Processing batch {batch_idx+1}/{100} (samples {i}-{end_idx-1})...\")\n",
    "    print(type(end_idx))\n",
    "    # try:\n",
    "        # Get batch and extract features\n",
    "    batch = ds['train'][i:end_idx]\n",
    "    \n",
    "    aaa = batch['audio']\n",
    "\n",
    "    batch_audio = [b[\"array\"] for b in aaa] \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataLoader' from 'datasets' (/home/andoni.sudupe/envs/myenv/lib/python3.12/site-packages/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Wav2Vec2Processor, HubertModel\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Audio, load_from_disk, DataLoader\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'DataLoader' from 'datasets' (/home/andoni.sudupe/envs/myenv/lib/python3.12/site-packages/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, HubertModel\n",
    "from datasets import load_dataset, Audio, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HubertModel.from_pretrained('Ansu/mHubert-basque-ASR')\n",
    "model.eval()\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_from_disk('/home/andoni.sudupe/mHubert_finetune/data/composite_eu/preprocessed_data')\n",
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 387426\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a custom collate function for padding\n",
    "def collate_fn_pad(batch):\n",
    "    audio_tensors = [torch.tensor(sample[\"input_values\"]) for sample in batch]\n",
    "    padded_audio = pad_sequence(audio_tensors, batch_first=True)\n",
    "    return padded_audio\n",
    "\n",
    "# Create a DataLoader with the custom collate function\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0649e-04,  1.0649e-04,  1.0649e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.3844e-04, -1.3844e-04, -1.3844e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-9.4134e-05, -9.4134e-05, -9.4134e-05,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-9.4094e-06, -9.4094e-06, -9.4094e-06,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6571e-04,  1.6571e-04,  1.6571e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5898e-04,  1.5898e-04,  1.5898e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store features\n",
    "all_features = []\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    input_values = batch.to(torch.float32)  # Extract audio data from the batch and ensure it's in the correct format\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_values, output_hidden_states=True)\n",
    "\n",
    "    # Extract features from the 9th hidden state\n",
    "    features = outputs.hidden_states[9].cpu().numpy()\n",
    "    all_features.append(features)\n",
    "\n",
    "# Concatenate all features into a single numpy array\n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "\n",
    "# Save features to disk\n",
    "np.save(\"features.npy\", all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from speechbrain.lobes.models.huggingface_transformers.hubert import (HuBERT)\n",
    "\n",
    "inputs = torch.rand([3, 2000])\n",
    "model_hub = \"facebook/hubert-large-ll60k\"\n",
    "save_path = \"savedir\"\n",
    "ssl_layer_num = [7,23]\n",
    "deduplicate =[False, True]\n",
    "bpe_tokenizers=[None, None]\n",
    "vocoder_repo_id = \"speechbrain/hifigan-hubert-k1000-LibriTTS\"\n",
    "kmeans_dataset = \"LibriSpeech\"\n",
    "num_clusters = 1000\n",
    "ssl_model = HuBERT(model_hub, save_path,output_all_hiddens=True)\n",
    "model = DiscreteSSL(save_path, ssl_model, vocoder_repo_id=vocoder_repo_id, kmeans_dataset=kmeans_dataset,num_clusters=num_clusters)\n",
    "# tokens, _, _ = model.encode(inputs,SSL_layers=ssl_layer_num, deduplicates=deduplicate, bpe_tokenizers=bpe_tokenizers)\n",
    "# sig = model.decode(tokens, ssl_layer_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(\"/home/andoni.sudupe/speechbrain/recipes/Euskara/TTS/vocoder/hifigan_discrete/results/hifi_gan/4322/save/codes/ESP00196.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubert_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
